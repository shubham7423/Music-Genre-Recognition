{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6d924ce6",
   "metadata": {},
   "source": [
    "# How To Run\n",
    "\n",
    "Download code from github repo (link: https://github.com/shubham7423/Music-Genre-Recognition). <br>\n",
    "Place this notebook in the same folder as mgr. <br>\n",
    "Install all libraries from requirements.txt file. <br>\n",
    "Download the raw audio files, preprocessed data and model weights from https://drive.google.com/file/d/1v4FYfKXk6gyzohnz6UZ7BT4cznHUSjFV/view and extract the contents in the same folder as mgr folder. <br>\n",
    "Path to the data and model weights can be updated in the mgr/configuration/configuration.yaml file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "495fd297",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run this cell to set the device to use.\n",
    "\n",
    "import mgr.configuration\n",
    "import torch\n",
    "import yaml\n",
    "\n",
    "CFG = mgr.configuration.load.load_configurations()\n",
    "CFG['device'] = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "with open('mgr\\configuration\\configuration.yaml', 'w') as file:\n",
    "    documents = yaml.dump(CFG, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5fafb9d",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34ff634d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mgr.preprocessing as preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "557c4260",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessing.process()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da9776c1",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95abb43e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mgr.train.transformer.cnn_transformer_v3 as cnn_transformer_v3\n",
    "import mgr.train.transformer.cnn_patch_transformer as cnn_patch_transformer\n",
    "import mgr.train.lstm.cnn_lstm as cnn_lstm\n",
    "import mgr.train.cnn.cnn as cnn\n",
    "import mgr.train.cnn.resnet as resnet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45e5df38",
   "metadata": {},
   "source": [
    "## Select model to train\n",
    "\n",
    "1.CNN <br>\n",
    "2.Resnet <br>\n",
    "3.CNN+LSTM <br>\n",
    "4.CNN+Transformer <br>\n",
    "5.CNN+Transformer(Patched)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11e7a721",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_option = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5be21108",
   "metadata": {},
   "outputs": [],
   "source": [
    "if model_option == 1:\n",
    "    model, History = cnn.start_training()\n",
    "    \n",
    "elif model_option == 2:\n",
    "    model, History = resnet.start_training()\n",
    "\n",
    "elif model_option == 3:\n",
    "    model, History = cnn_lstm.start_training()\n",
    "\n",
    "elif model_option == 4:\n",
    "    model, History = cnn_transformer_v3.start_training()\n",
    "    \n",
    "elif model_option == 5:\n",
    "    model, History = cnn_patch_transformer.start_training()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4bd48b2",
   "metadata": {},
   "source": [
    "# Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "269a8546",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mgr.predict as predict\n",
    "import mgr\n",
    "\n",
    "import mgr.train.transformer.cnn_transformer_v3 as cnn_transformer_v3\n",
    "import mgr.train.transformer.cnn_patch_transformer as cnn_patch_transformer\n",
    "import mgr.train.lstm.cnn_lstm as cnn_lstm\n",
    "import mgr.train.cnn.cnn as cnn\n",
    "import mgr.train.cnn.resnet as resnet\n",
    "\n",
    "import torch\n",
    "import os\n",
    "\n",
    "CFG = mgr.configuration.load_configurations()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b492c85",
   "metadata": {},
   "source": [
    "# Model Architecture:\n",
    "1.CNN <br>\n",
    "2.Resnet <br>\n",
    "2.CNN+LSTM <br>\n",
    "3.CNN+Transformer(v3) <br>\n",
    "4.CNN+Transformer(Patched)\n",
    "\n",
    "For windows do not use .mp3 file <br>\n",
    "Provide path to the audio file to (AUDIO_PATH) variable which is longer than 3 seconds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "162d0070",
   "metadata": {},
   "outputs": [],
   "source": [
    "AUDIO_PATH = \"sample_audio/electronic_1.wav\"\n",
    "\n",
    "model_architecture = 5\n",
    "\n",
    "model = None\n",
    "\n",
    "if model_architecture == 1:\n",
    "    model = cnn.getModel()\n",
    "    ckpts = torch.load(os.path.join(CFG['cnn']['train']['save_model_at'], \"cnn.pt\"), map_location=CFG['device'])\n",
    "    model.load_state_dict(ckpts['model'])\n",
    "    \n",
    "elif model_architecture == 2:\n",
    "    model = resnet.getModel()\n",
    "    ckpts = torch.load(os.path.join(CFG['cnn']['train']['save_model_at'], \"resnet.pt\"), map_location=CFG['device'])\n",
    "    model.load_state_dict(ckpts['model'])\n",
    "\n",
    "elif model_architecture == 3:\n",
    "    model = cnn_lstm.getModel()\n",
    "    ckpts = torch.load(os.path.join(CFG['lstm']['train']['save_model_at'], \"lstm.pt\"), map_location=CFG['device'])\n",
    "    model.load_state_dict(ckpts['model'])\n",
    "\n",
    "elif model_architecture == 4:\n",
    "    model = cnn_transformer_v3.getModel()\n",
    "    ckpts = torch.load(os.path.join(CFG['transformer']['train']['save_model_at'], \"transformerv3.pt\"), map_location=CFG['device'])\n",
    "    model.load_state_dict(ckpts['model'])\n",
    "    \n",
    "elif model_architecture == 5:\n",
    "    model = cnn_patch_transformer.getModel()\n",
    "    ckpts = torch.load(os.path.join(CFG['transformer']['train']['save_model_at'], \"cnn_patch_transformer.pt\"), map_location=CFG['device'])\n",
    "    model.load_state_dict(ckpts['model'])\n",
    "    \n",
    "else:\n",
    "    print(\"Enter valid choice!!\")\n",
    "\n",
    "if model is not None:\n",
    "    print(\"Top 3 genres: \", predict.predict(model, AUDIO_PATH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27f3e66b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
